{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48954bdb",
   "metadata": {},
   "source": [
    "# 03 — Claim Frequency Modeling\n",
    "\n",
    "**Goal:** Build a Poisson GLM for claim frequency with `log(Exposure)` as\n",
    "offset. Evaluate using Poisson deviance and lift charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4be28",
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(\"\")), \"\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.float_format\", \"{:,.4f}\".format)\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d637cb5",
   "metadata": {},
   "source": [
    "## 1. Load cleaned data & engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config import FREQ_PROCESSED, CATEGORICAL_COLS, NUMERIC_COLS, RANDOM_STATE, TEST_SIZE\n",
    "from src.features.build_features import add_log_density, build_all_features\n",
    "\n",
    "freq = pd.read_csv(FREQ_PROCESSED)\n",
    "freq = build_all_features(freq)\n",
    "\n",
    "print(\"Shape after feature engineering:\", freq.shape)\n",
    "display(freq.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b2f71",
   "metadata": {},
   "source": [
    "## 2. Prepare design matrix\n",
    "\n",
    "Encode categoricals via one-hot encoding (drop first to avoid collinearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categoricals\n",
    "freq_encoded = pd.get_dummies(freq, columns=CATEGORICAL_COLS, drop_first=True, dtype=float)\n",
    "\n",
    "# Define feature columns (all numeric + dummies, excluding targets/ID)\n",
    "exclude = {\"IDpol\", \"ClaimNb\", \"Exposure\", \"HasClaim\",\n",
    "           \"VehAgeBin\", \"DrivAgeBin\", \"BonusMalusBin\"}\n",
    "feature_cols = [c for c in freq_encoded.columns if c not in exclude]\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(\"Sample features:\", feature_cols[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c43c3",
   "metadata": {},
   "source": [
    "## 3. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    freq_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Train: {train_df.shape[0]:,}  |  Test: {test_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b08e57",
   "metadata": {},
   "source": [
    "## 4. Fit Poisson GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4713968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.frequency import PoissonFrequencyModel\n",
    "\n",
    "model = PoissonFrequencyModel(feature_cols)\n",
    "model.fit(train_df, target=\"ClaimNb\", exposure=\"Exposure\")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b7d5d",
   "metadata": {},
   "source": [
    "## 5. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "\n",
    "train_df[\"pred_freq\"] = model.predict(train_df, exposure=\"Exposure\")\n",
    "test_df[\"pred_freq\"] = model.predict(test_df, exposure=\"Exposure\")\n",
    "\n",
    "print(\"Train — observed vs predicted mean:\")\n",
    "print(f\"  Observed:  {train_df['ClaimNb'].mean():.5f}\")\n",
    "print(f\"  Predicted: {train_df['pred_freq'].mean():.5f}\")\n",
    "\n",
    "print(\"\\nTest — observed vs predicted mean:\")\n",
    "print(f\"  Observed:  {test_df['ClaimNb'].mean():.5f}\")\n",
    "print(f\"  Predicted: {test_df['pred_freq'].mean():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097039bc",
   "metadata": {},
   "source": [
    "## 6. Evaluation — Poisson deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.metrics import deviance_poisson, lift_table, gini_coefficient\n",
    "\n",
    "dev_train = deviance_poisson(train_df[\"ClaimNb\"], train_df[\"pred_freq\"])\n",
    "dev_test = deviance_poisson(test_df[\"ClaimNb\"], test_df[\"pred_freq\"])\n",
    "\n",
    "print(f\"Poisson deviance — train: {dev_train:.5f}\")\n",
    "print(f\"Poisson deviance — test:  {dev_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6861d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_train = gini_coefficient(train_df[\"ClaimNb\"].values, train_df[\"pred_freq\"].values)\n",
    "gini_test = gini_coefficient(test_df[\"ClaimNb\"].values, test_df[\"pred_freq\"].values)\n",
    "print(f\"Gini — train: {gini_train:.4f}\")\n",
    "print(f\"Gini — test:  {gini_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750f979",
   "metadata": {},
   "source": [
    "## 7. Lift chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bce597",
   "metadata": {},
   "outputs": [],
   "source": [
    "lift = lift_table(\n",
    "    test_df[\"ClaimNb\"].values,\n",
    "    test_df[\"pred_freq\"].values,\n",
    "    exposure=test_df[\"Exposure\"].values,\n",
    "    n_bins=10,\n",
    ")\n",
    "display(lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = range(len(lift))\n",
    "ax.bar(x, lift[\"observed_mean\"], width=0.4, label=\"Observed\", color=\"steelblue\", align=\"center\")\n",
    "ax.bar([i + 0.4 for i in x], lift[\"predicted_mean\"], width=0.4, label=\"Predicted\", color=\"coral\", align=\"center\")\n",
    "ax.set_xticks([i + 0.2 for i in x])\n",
    "ax.set_xticklabels([f\"D{i+1}\" for i in x], rotation=0)\n",
    "ax.set_xlabel(\"Decile (by predicted frequency)\")\n",
    "ax.set_ylabel(\"Mean Claim Count\")\n",
    "ax.set_title(\"Frequency Model — Lift Chart (Test Set)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e57a7",
   "metadata": {},
   "source": [
    "## 8. Residual diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098af3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deviance residuals\n",
    "test_df[\"resid_deviance\"] = model.results_.resid_deviance[test_df.index] if hasattr(\n",
    "    model.results_, \"resid_deviance\"\n",
    ") else test_df[\"ClaimNb\"] - test_df[\"pred_freq\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(test_df[\"pred_freq\"], test_df[\"resid_deviance\"],\n",
    "                alpha=0.1, s=2, color=\"steelblue\")\n",
    "axes[0].axhline(0, color=\"red\", linewidth=0.8)\n",
    "axes[0].set_xlabel(\"Predicted Frequency\")\n",
    "axes[0].set_ylabel(\"Residual\")\n",
    "axes[0].set_title(\"Residuals vs. Predicted\")\n",
    "\n",
    "axes[1].hist(test_df[\"resid_deviance\"].clip(-5, 5), bins=100,\n",
    "             color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"Residual Distribution\")\n",
    "axes[1].set_xlabel(\"Residual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da7aed",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Fitted Poisson GLM with `log(Exposure)` offset on the full feature set\n",
    "- Model achieves reasonable Poisson deviance and positive Gini on test data\n",
    "- Lift chart shows good monotonic separation across predicted-frequency deciles\n",
    "- Key predictors: `BonusMalus`, `DrivAge`, `Density`, `Area`, `VehPower`\n",
    "- Next: severity modeling in notebook 04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Insurance Risk",
   "language": "python",
   "name": "insurance-risk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
